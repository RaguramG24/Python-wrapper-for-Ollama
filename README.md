# Python-wrapper-for-Ollama

Just trying out hosting LLMs locally using Ollama. Came across Tech with Tim tutorial and modified the code to gather input from user to generate response

Source: https://github.com/techwithtim/OllamaTutorial.git package.py file
