# Python-wrapper-for-Ollama

Just trying out hosting LLMs locally using Ollama. Came across Tech with Tim tutorial and modified the code to gather input from user to genrate response

Source: https://github.com/techwithtim/OllamaTutorial/blob/main/package.py
